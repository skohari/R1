---
title: 'skidV2'
author: 'Shahzeb Kohari'
date: '`r Sys.Date()`'
output:
  html_document:
    code_folding: show
    fig_width: 8
    fig_height: 6
    fig_caption: true
    number_sections: true
    toc: true
    theme: yeti
    highlight: textmate 
---

# Introduction: 

This is my first script.
The dataset detail are given in the following sub-section`. 

data set as it seems to be well formatted and should be a nice introduction to R. 

```{r, include=FALSE}
# Many standard libraries are already installed, such as randomForest
library("dplyr")
library("mice") #used for inputting missing data
library("ggplot2")
library("scales")
library("ggthemes")
library("randomForest")
library(knitr)
library(corrplot)
library(caret)
library(readr) # CSV file I/O, e.g. the read_csv function
library(C50)
library("ROCR")
library(pROC); 
library(plotROC)
library(dplyr)
library(nycflights13)
library(stargazer)
library(pscl)
library(MKmisc)
library(survey)



# date related functions
is.POSIXct  <- function(x) inherits(x, "POSIXct")
is.POSIXlt  <- function(x) inherits(x, "POSIXlt")
is.POSIXt   <- function(x) inherits(x, "POSIXt")
is.Date     <- function(x) inherits(x, "Date")

```

## Loading the data

We load the data into a single data structure so that we can pre-process in one go. 
The following are the data-related declarations required, primarily `allData` and `responseVariable`.

```{r}

data(churn) 						        # DECLARATION POINT ~

allData             <- flights ;		        # DECLARATION POINT ~ RData Frame Object
responseVariable    <- "arr_delay" ;			# DECLARATION POINT ~ Variable "Name"
modelChoice         <- 1;                      # DECLARATION POINT ~ 1 for LINEAR, 2 for LOGISTIC

allData             <- rbind(churnTrain, churnTest)  ;		        # DECLARATION POINT ~ RData Frame Object
responseVariable    <- "churn" ;			    # DECLARATION POINT ~ Variable "Name"
modelChoice         <- 2;                       # DECLARATION POINT ~ 1 for LINEAR, 2 for LOGISTIC

split               <- 0.60 ;                   # DECLARATION POINT ~ Dev/Val split
hc                  <- 0.75 ;                   # DECLARATION POINT ~ High Correlation Threshold

```

```{r, echo= T}
rawDf <- as.data.frame(allData[complete.cases(allData),], stringsAsFactors = T) # dim(rawDf);

multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```

### Data Splitting

Allocation of data to certain tasks (e.g., model development, performance validation) is an important aspect of modeling. 
For this example, the primary interest is to predict the **`r responseVariable`** for future observations, which is not the 
same population as the data used to build the model. This means that, to some degree, we are testing how well the 
model _extrapolates_ to a different population. If we were interested in predicting from the same population 
(i.e., interpolation), taking a simple random sample of the data would be more appropriate. How the training and test sets 
are determined should reflect how the model will be applied.

The development sample for this run will be **`r split*100`%** of all data available. 
The remaining will be used for performance validation.
Function `createDataPartition()` causes balanced splits of the data. If the class argument to this function is a factor (as in this case), 
the random sampling occurs within each class and should preserve the overall class distribution of the data. 
The function requires a random number (set.seed) to be set.

The six-point summary of all variables in given below.

```{r, echo=T}

rawDf[,'responseVariable']  <- as.numeric(as.factor(rawDf[, responseVariable])) - 1     # Converting to `0/1's
rawDf[, responseVariable ]  <- NULL               # Remove the original responseVariable

set.seed(123)
inTraining 	<- createDataPartition(rawDf$responseVariable, p= split, list= FALSE)
devDf 		<- rawDf[ inTraining,];  
valDf 		<- rawDf[-inTraining,];

# Variable manipulations' final stop;
devDf$fakeNum  <- -1* devDf[,6];
valDf$fakeNum  <- -1* valDf[,6];
devDf$fakeChar <- LETTERS[round(runif(nrow(devDf), 1, 5),1)]; #str(devDf);
valDf$fakeChar <- LETTERS[round(runif(nrow(valDf), 1, 5),1)]; #str(valDf);

summary(devDf)

```

## Data details


### Raw data

Below is an overview of the data before and after the dev/val split. 
The *1* extra variable in the post-split dataframes is the newly created `responseVariable` that will be used 
in the development exercise.

Object | Data | Observations | Variables
------------- | ------------- | ------------- | -------------
`rawDf` | `r substitute(rawDf)`  | `r dim(rawDf)[1] ` | `r dim(rawDf)[2] `
`devDf` | Development data frame | `r dim(devDf)[1] ` | `r dim(devDf)[2] `
`valDf` | Validation data frame  | `r dim(valDf)[1] ` | `r dim(valDf)[2] `



#### `devDf` variable types

A snapshot of the different classes of variables types and some values is given below. 

```{r, include= T}

set.seed(1)
allVars 		    <- NULL; 
allVars.num         <- NULL; 
allVars.categ       <- NULL;
allVars.char        <- NULL; 
allVars.date        <- NULL; 

devDf.num.select    <- NULL
devDf.categ.select  <- NULL
devDf.char.select   <- NULL
devDf.date.select   <- NULL

all	            <- devDf; all$responseVariable = NULL

allVars 		<- colnames(all);	                            #length(allVars);
allVars.num 	<- colnames(all[sapply(all, is.numeric)]); 	    #length(allVars.num);
allVars.categ 	<- colnames(all[sapply(all, is.factor)]); 	    #length(allVars.categ);
allVars.char    <- colnames(all[sapply(all, is.character)]);    #length(allVars.char); 
allVars.date    <- colnames(all[sapply(all, is.POSIXt)]);       #length(allVars.date);

rm(all);

devDf.num          <- data.frame(devDf[, allVars.num]);     colnames(devDf.num)     <- allVars.num;    str(devDf.num);     
devDf.categ        <- data.frame(devDf[, allVars.categ]);   colnames(devDf.categ)   <- allVars.categ;  str(devDf.categ);   
devDf.char         <- data.frame(devDf[, allVars.char]);    colnames(devDf.char)    <- allVars.char;   str(devDf.char);    
devDf.date         <- data.frame(devDf[, allVars.date]);    colnames(devDf.date)    <- allVars.date;   str(devDf.date);    

```
Below is an overview of the variable *types* in the development sample.

 Variable Class | Type | Count
 ------------- | ------------- | -------------
 **`allVars`**      | **All Variables** | **`r length(allVars) `**
 `allVars.num`  | Numeric       | `r length(allVars.num) `
 `allVars.categ`| Categorical   | `r length(allVars.categ) ` 
 `allVars.char` | Character     | `r length(allVars.char) ` 
 `allVars.date` | Date          | `r length(allVars.date)`
 responseVariable | Factor      | 1






### Variables XXX
There are **`r length(allVars)`** variables that can be considered, of which **`r length(allVars.num)`** are numeric, **`r length(allVars.categ)`** are factors, 
and **`r length(allVars.char)`** are character.  **`r length(allVars.date)`** is (are) *Date* type variable(s).









## Variable Reduction
In this section we choose the top 10 variables for model tuning. As a first cut, we use Forward Stepwise process.


### Stepwise Process




### CART Tree



### Correlations between numeric variables
Before we get too deep into the data, let's have a look at what we're dealing with.
Correlations between numeric variables need to checked; and highly 
correlated variables need to be dropped. 'High' correlation threhold is set at `r hc`.



#### *All* numeric variables and their correlation coeffs
```{r}
descrCorr       <- cor(devDf.num)       #correlation matrix
descrCorr[is.na(descrCorr)] <- 0                            # Missing correlations (NA) are hardcoded as 0
corrplot(descrCorr, method= "color", type= "lower", order= "hclust", tl.cex= 0.75, tl.col= "black", tl.srt= 45, addCoef.col="grey", 
    number.cex = 7/ncol(devDf.num), number.digits=2)


highCorr            <- findCorrelation(descrCorr, hc)   #index of highly correlated vars;
devDf.num.select    <- data.frame(devDf.num[, -highCorr]);      

# Variables that are dropped
# colnames(devDf.num[, highCorr])
# colnames(devDf.num.select) 
# ncol(devDf.num.select)
```

#### *Select* variables after adjusting for correlation.
```{r}

descrCorr       <- cor(devDf.num.select) #correlation matrix
descrCorr[is.na(descrCorr)] <- 0
corrplot(descrCorr, method = "color", type="lower", order="hclust", tl.cex = 0.75, tl.srt = 45, tl.col= "black", addCoef.col="grey",
    number.cex = 7/ncol(devDf.num.select), number.digits=2)

```


### Visualising the numeric variables
Listing of the numeric variables.

```{r}
Df     	<- devDf[,c( 'responseVariable', colnames(devDf.num.select) )] 
for (i in 2:length(Df)) {
    p1 <- ggplot(Df, aes(x=(Df)[,i], fill=as.factor(responseVariable))) + geom_density(alpha = 0.3)  + xlab(colnames(devDf.num.select)[i-1])
    p2 <- ggplot(Df, aes((Df)[,i], y = responseVariable)) + geom_point() + xlab(colnames(devDf.num.select)[i-1]) +
	stat_summary(fun.y = "mean", colour = "steelblue", size = 2, geom = "point")

    multiplot(p1, p2, cols=1)
}
```



### Visualising the character variables
Listing of the character variables:
```{r}
## Bar Charts for all character variables~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#for (i in 1:length(colnames(devDf.char)) ){ 
#	x = devDf[, allVars.char[i]]
#	#print(aggregate(caretDf[, 'responseVariable'], list(x),  mean)) # Edit for maximum display
#	#print(ggplot(devDf, aes_string(as.name(colnames(devDf.char[i])),'responseVariable')) 
#	    + geom_bar(stat = "summary", fun.y = "mean") + theme_bw())
#	print(ggplot(devDf, aes(as.name(colnames(devDf.char[i])),responseVariable)) + geom_bar(stat = "summary", fun.y = "mean") + theme_bw())
#}

# or

str(devDf.char);
colnames(devDf.char);
Df     	<- devDf[,c( 'responseVariable', colnames(devDf.char) )] 
str(Df)
lapply(Df,  function(fx) {
	(ggplot(Df, aes(x= reorder(fx, -responseVariable),y= responseVariable)) + geom_bar(stat= "summary", fun.y= "mean") 
	    + theme_bw() + ylab("Mean of responseVariable")  )
})
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

```





### Selected variables
The variables listed in `allVars.select` are the final set of variables selected for the model.

#### Numeric
The **`r ncol(devDf.num.select)`** variables that are selected are stored in the vector `allVars.num.select`.
```{r, echo= F} 
allVars.num.select <- colnames(devDf.num.select);
allVars.num.select;
```

#### Categorical
The **`\r ncol(devDf.categ.select)`** variables that are selected are stored in the vector `allVars.categ.select`.
```{r, echo= F} 
allVars.categ.select <- colnames(devDf.categ.select)
allVars.categ.select;
```

#### Character
The **`\r ncol(devDf.char.select)`** variables that are selected are stored in the vector `allVars.char.select`.
```{r, echo= F} 
allVars.char.select <- colnames(devDf.char.select)
allVars.char.select;

```

#### Date
The **`\r ncol(devDf.date.select)`** variables that are selected are stored in the vector `allVars.date.select`.
```{r, echo= F} 
allVars.date.select <- colnames(devDf.char.select)
allVars.date.select;
allVars.select <- c(allVars.num.select, allVars.categ.select, allVars.char.select, allVars.date.select)

```
Below is an overview of the variable *types* in the development sample.

 Variable Class | Type | Count
 ------------- | ------------- | -------------
 **`allVars`**      | **All Variables** | **`r length(allVars) `**
 `allVars.num.select`  | Numeric       | `\r length(allVars.num.select) `
 `allVars.categ.select`| Categorical   | `\r length(allVars.categ.select) ` 
 `allVars.char.select` | Character     | `\r length(allVars.char.select) ` 
 `allVars.date.select` | Date          | `\r length(allVars.date.select)`
 responseVariable | Factor      | 1

### Dropped variables

#### Numeric
The **`r ncol(devDf.num[, highCorr])`** variables that are dropped are stored in the vector `devDf.num.select[, highCorr]` 
```{r, echo=F} 
colnames(devDf.num[, highCorr])
```

#### Categorical
The **`\r ncol(devDf.categ[, highCorr])`** variables that are dropped are stored in the vector `devDf.categ.select[, highCorr]` 
```{r, echo=F} 
#colnames(devDf.categ[, highCorr])
```

#### Character
The **`\r ncol(devDf.categ[, highCorr])`** variables that are dropped are stored in the vector `devDf.char.select[, highCorr]` 
```{r, echo=F} 
#colnames(devDf.char[, highCorr])
```










## Model Training [Coeff Generation]
One of the simplest models that can be built for a continuous response variable is the Linear Model. 

Presented below is the `r ifelse(modelChoice==1, "linear", "logistic") ` regression model with all the variables listed under sections `Selected variables` 
stored under `allVars.select`. This is the final list.

```{r}

#caretDf     <- devDf[, c('responseVariable', allVars.select) ]
caretDf     <- devDf[, c('responseVariable', allVars.num.select) ]


# Model Training
# control parameters
lmControl <- trainControl(method= "repeatedcv" 
                        ,number= 4                    
                        ,repeats= 2          
)

glmControl <- trainControl(method = "repeatedcv" 
                        ,repeats = 5
)

set.seed(825)

ifelse(     modelChoice == 1,
        lmFit   <- train(responseVariable ~ . 
                    ,data= caretDf
                    ,method= "lm" 
                    ,trControl= lmControl
                    ,metric= "Rsquared"
    )
    ,ifelse(modelChoice == 2,
        lmFit   <- train(responseVariable ~ . 
                    ,data= caretDf
                    ,method= "glm" ,family= "binomial"
                    ,trControl= glmControl
        )
    ,)
)

ifelse(modelChoice == 1,
    lmFit <- lm(responseVariable ~ . , data= caretDf
    ) 
    ,ifelse(modelChoice == 2,
        lmFit <- glm(responseVariable ~ . , data= caretDf, family = "binomial"
        ) 
        ,
    )
)
 


```

### Model Coefficients
Coefficients of independent variables in the linear equation are given below.

```{r}
#summary(lmFit$finalModel)
summary(lmFit)

```
```{r, results= 'asis'}

stargazer(lmFit
            ,type= 'html'
            ,intercept.bottom = FALSE
            ,digits = 4
)

```

### Trained Model Diagnostics
A logistic regression model has been built and the coefficients have been examined. However, some critical questions remain. 
Is the model any good? How well does the model fit the data? Which predictors are most important? Are the predictions accurate? 
Listed below are some of the Diagnostics tests.



####  Hosmer-Lemeshow Test
Another approch to determining the goodness of fit is through the Homer-Lemeshow statistics, which is computed on data after 
the observations have been segmented into groups based on having similar predicted probabilities. 
It examines whether the observed proportions of events are similar to the predicted probabilities of occurence in 
subgroups of the data set using a pearson chi square test. Small values with large p-values indicate a good fit to the data 
while large values with p-values below 0.05 indicate a poor fit. 
The null hypothesis holds that the model fits the data.

```{r}
HLgof.test(fit = fitted(lmFit), obs = devDf$responseVariable)

```

#### Wald Test
Wald test is used to evaluate the statistical significance of *each* coefficient in the model and is calculated by taking 
the ratio of the square of the regression coefficient to the square of the standard error of the coefficient. 
The idea is to test the hypothesis that the coefficient of an independent variable in the model is significantly 
different from zero. If the test fails to reject the null hypothesis, 
this suggests that removing the variable from the model will not substantially harm the fit of that model.

```{r}

list2 <- as.list(allVars.num.select)
for(i in 1:length(list2)) {
    print(list2[[i]])
    #print(regTermTest(lmFit$finalModel, list2[[i]]))
}
rm(list2);

```
### Variable Importance

To assess the relative importance of individual predictors in the model, we can also look at the absolute value of the 
t-statistic for each model parameter. This technique is utilized by the `varImp` function in the `caret` package for 
general and generalized linear models.

The variable importance is ordered and relative to the most important variable in the model.

```{r}
varImp(lmFit)
```

### Trained Model Performance

Using the model coefficients, various metrics can be used to evaluate performance.

For regression models:
R2 is very popular. In many complex models, the notion of the model degrees of freedom is difficult. 
Unadjusted R2 can be used, but does not penalize complexity. 
RMSE, the root mean square error, is a common metric for understanding the performance .
Spearman's correlation may be applicable for models that are used to rank samples.

```{r}

```

## Model Testing [Prediction] *(on maximum 40000 obs)*

The generated model coefficients are tested on the validation data. *In this run, they're run on the maximum of 40000. 
This condition should be removed in the final runs.*  

```{r}

test.valDf      <- valDf[1:(min(40000, nrow(valDf))),];

ifelse( modelChoice == 1
        ,test.valDf[,'predictionVariable']   <- predict(lmFit, newdata = test.valDf, type='link')
    ,ifelse(modelChoice == 2
        ,test.valDf[,'predictionVariable']   <- predict(lmFit, newdata = test.valDf, type='response')
    ,)
)
str(test.valDf)

```


### Classification Rate (assuming cut-off of **0.70**), ANOVA, and ROC
When developing models for prediction, the most critical metric regards how well the model does in predicting the 
target variable on out of sample observations. The process involves using the model estimates to predict values on the training set. 
Afterwards, we will compared the predicted target variable versus the observed values for each observation. 


The difference between the null deviance and the residual deviance shows how our model is doing against the null model (a model with only the intercept). The wider this gap, the better. Analyzing the table we can see the drop in deviance when adding each variable one at a tim

While no exact equivalent to the R2 of linear regression exists, the McFadden R2 index can be used to assess the model fit.

```{r, include=FALSE}
ifelse(modelChoice == 2,
        mc2 <- list(
                    confusionMatrix((test.valDf$predictionVariable > .70), (test.valDf$responseVariable == 1))
                    ,anova(lmFit, test="Chisq")
                    ,pR2(lmFit)
                    )
        ,
)
```
```{r}
print(mc2)
```


### Comparison of Actual v/s Predicted *(FOR VALUES UP TO 200)*

`r ifelse(is.numeric(test.valDf$responseVariable), print("Since valDf$responseVariable is numeric we can generate AUC and other lift statistics to assess the performance."),        print("Since valDf$responseVariable is a factor we can generate a confusion matrix to assess the accuracy and Kappa statistics."))`

```{r}

#

if (is.numeric(test.valDf$responseVariable)) {
        pr  <- prediction(test.valDf$predictionVariable, test.valDf$responseVariable)
        auc <- performance(pr, measure = "auc")
        auc <- auc@y.values[[1]]
        a   <- list(
                    ggplot(test.valDf[test.valDf$predictionVariable < 200,], aes(predictionVariable, responseVariable )) + geom_point() + theme_bw()
                    ,ggplot() + geom_roc(aes(d = responseVariable, m = predictionVariable), test.valDf)  + theme_bw()
                    ,paste("AUC ->", round(auc,4))
                    )
} else {(is.character(test.valDf$responseVariable)) || (is.factor(test.valDf$responseVariable))
        a   <- confusionMatrix(test.valDf$predictionVariable, test.valDf$responseVariable)
}                
print(a); rm(a);


```             








# Conclusion

At the time of writing...

Thank you for taking the time to read my report. Please get in touch if you have any questions.
Special thanks to the `R` Core Team, Kaggle, and developers of `R` packages, especially `caret`.
I would like to credit [Megan Ridsal](https://www.kaggle.com/mrisdal/titanic/exploring-survival-on-the-titanic) a great tutorial that i've taken great inspiration from.





by(dfe, ii,function(x) {x})

